![Local Guide Chatbot Screenshot](chat-screenshot.png)

# Local-Guide Chatbot

## Overview

A full-stack application that lets users chat with a locally-trained Q&A model about tourism in Rwanda. It comprises a FastAPI backend that serves the model and a modern React (Vite + TypeScript + Tailwind CSS) frontend. Everything can be run locally with Python and Node, or packaged into a single container via Docker.

---

## üìÇ Repository Structure

```
.
‚îú‚îÄ‚îÄ api/                  # FastAPI application (REST + Streaming endpoints)
‚îÇ   ‚îú‚îÄ‚îÄ main.py           # Entrypoint for Uvicorn / Docker
‚îÇ   ‚îú‚îÄ‚îÄ pipeline.py       # Inference & preprocessing pipeline
‚îÇ   ‚îî‚îÄ‚îÄ clean_data.py     # Utility script for dataset cleaning
‚îÇ
‚îú‚îÄ‚îÄ frontend/             # React + Vite client application
‚îÇ   ‚îú‚îÄ‚îÄ src/              # Front-end source (components, pages, hooks, ui)
‚îÇ   ‚îî‚îÄ‚îÄ public/           # Static assets served by Vite
‚îÇ
‚îú‚îÄ‚îÄ notebook/
‚îÇ   ‚îî‚îÄ‚îÄ LocalGuideModel.ipynb  # Jupyter notebook used to train / fine-tune the model
‚îÇ
‚îú‚îÄ‚îÄ scripts/              # Stand-alone Python helpers (training, preprocessing)
‚îÇ   ‚îú‚îÄ‚îÄ dataset_generator.py
‚îÇ   ‚îú‚îÄ‚îÄ preprocessing.py
‚îÇ   ‚îî‚îÄ‚îÄ trainer.py
‚îÇ
‚îú‚îÄ‚îÄ rwanda_qa_cleaned.csv # Curated Q&A dataset (public)
‚îÇ
‚îú‚îÄ‚îÄ Dockerfile            # Production-ready image combining backend & built frontend
‚îú‚îÄ‚îÄ pyproject.toml        # Poetry / PEP-621 project configuration
‚îî‚îÄ‚îÄ README.md             # You are here
```

> The tree above omits all files and directories ignored by Git (virtual-envs, caches, etc.).

---

## ‚öôÔ∏è Prerequisites

| Tool                 | Version (tested) | Notes                              |
| -------------------- | ---------------- | ---------------------------------- |
| Python               | 3.11             | Backend + training scripts         |
| uv (package manager) | 0.1+             | Lightning-fast dependency resolver |
| Node.js / npm        | 20 / 10          | Frontend dev & production build    |
| Docker (optional)    | 24+              | One-click containerised deployment |

Any later version _should_ also work.

---

## üöÄ Quick Start (local dev)

1. **Clone & install backend dependencies**

   ```bash
   git clone https://github.com/your-org/Local-guide-chatbot.git
   cd Local-guide-chatbot

   # Create & activate an isolated environment managed by uv
   uv venv .venv
   source .venv/bin/activate

   # Sync dependencies exactly as captured in uv.lock (blazing-fast)
   uv pip sync
   ```

2. **Install & run the frontend**

   ```bash
   cd frontend
   npm install   # or pnpm / bun
   npm run dev   # hot-reloads on http://localhost:5173
   ```

---

## ü§ñ Using / Retraining the Model

The conversational model powering the chatbot is prototyped in `notebook/LocalGuideModel.ipynb`.

1. Launch the notebook (e.g., `jupyter lab notebook/LocalGuideModel.ipynb`).
2. Execute the cells to download the base model, fine-tune on `rwanda_qa_cleaned.csv`, and export weights.
3. Exported checkpoints are automatically picked up by `api/pipeline.py`. By default the pipeline looks for a directory named `model` at the project root ‚Äì simply move / copy your trained weights there.

_No external API keys are required ‚Äì the entire model runs locally._

If you do not wish to retrain, you can download a pre-trained checkpoint (see project releases) and place it in the same `model/` folder.

---

## üê≥ Docker Deployment

The provided `Dockerfile` builds a production image that serves _both_ the compiled React front-end **and** the FastAPI backend in one container.

### Build

```bash
# From project root
docker build -t localguide-chatbot:latest .
```

---

## üõ†Ô∏è Useful Scripts

- `scripts/trainer.py` ‚Äì Train / fine-tune the model headless (no notebook).
- `scripts/dataset_generator.py` ‚Äì Augment data from raw sources.
- `scripts/preprocessing.py` ‚Äì Text cleaning helpers shared across pipeline & trainer.

Run any script with `python -m scripts.trainer --help` for CLI options.

---

Made with ‚ù§ By Me.
